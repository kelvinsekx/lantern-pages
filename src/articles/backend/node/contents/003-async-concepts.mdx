---
title: "Node Async and Event Loop"
description: ""
published_date: "09/07/2025"
last_updated_date: "09/07/2025"
syllabus_code: "BAC001"
authors: "kelvinsekx"
---

Node is fundamentally built on async and the event loop fundamentals. When we say things run in async in Node, we mean they run asynchronously.
Async is both a concept and keyword in Node. We will discuss what the keyword does later in this chapter. For now, let's focus on understanding it as a core concept.

Async means tasks are not forced to wait after another. If something wants more time, it should have it while the program goes on with the rest of the tasks.

For example, **the process of sewing by one person synchronously**. As a taylor, you can not stich a cloth until they are cut in pieces patterns. After cutting, you would have to weave (depending on the material) before sewing and so on. In a nutshell, you can not go on with another process until the first is done.

But let's use another example with **a Baker who bakes asynchromously**. They start by spreading cream while the machine is mixing the cake. If it is done to taste, you can leave what you are doing to go back to the mixed cake.

These scenarios represent Async and Sync concepts well. Async guarantees your node program can keep running while another piece of the program is doing something else that usually takes time or slow. These kind of operations are taken off the execution flow;

Asyn is expressed in 3 broad patterns in javascript and node: Callbacks, Promise and Async/Await.

## Callbacks

Before javascript as a language empowered us with an intuitive way of handling async tasks, Node gave us Callbacks.

Callbacks are functions that are called after an async task is done.

Using our baking example, imagine giving an instruction that if the bake is done smoothing, a sound should peep.

```bash
cake("be mixing", (err, done){
    if(!err){
        done(peep)
    }
})
```

A popular computer example would be reading from the drive or filesystem. Until recently with faster computers, it takes a substantial time to read from drives. You don't want to delay your entire program waiting for a feedback from your drive.

**Synchronously reading a file**

```bash
let fileName
console.log("Hello")
// prints "Hello" -> GoToNextLine

fileName = filesystem.SyncRead('file')
// takes 10 secs -> call done() -> GoToNextLine

console.log(fileName)
// prints "FileName.txt" -> ends
```

**ASynchronously reading a file**

```bash
let fileName
console.log("Hello")
// prints "Hello" -> GoToNextLine

filesystem.AsyncRead('file', (err, done))
// leaves execution flow -> GoToNextLine immediately -> takes 10 secs in background -> call done()

console.log(fileName)
// prints undefined -> ends
```

<LongAside subject={'A little beyond: Async in series and parallel'}>

Although most of our examples while doing asyn operations would be with a sigle identity, in rare cases, often than not, you would have to make async operations for multiple things at a time. For example an array of items.

An example where this shine is trying to read all the files in a directory. You can either do these async operations in series or parallel. Let's make an example of reading a folder and list the length of the files in the directory/folder.

We might be tempted to do this.

```bash
fs.readdir('foldername', (err, files){
    if(err) throw new Error(err)
    files.forEach((f)=> {
        fs.readFile(f, (err, result){
            if(err){
                throw new Error(err)
            }
            console.log(result.length)
        })
    })
})
```

The problem with our former example is that the length of files would not come in the order of the files in our directory.

To solve this, we can make the operations in series. One after another, and what else algorithm shines here if not recursion. See example below:

```bash
import fs from "fs";
import path from "path";

fs.readdir("ddd", (err, files)=>{
  if(err) throw new Error(err);

  function readFiles(i){
    if(i >=files.length) return; // exit
    fs.readFile(path.join("ddd", files[i]), (err, content)=> {
        if(err) throw new Error(err);
        console.log(content.toString())
        readFiles(i+1)
    })
 }

 readFiles(0)

})
```

There are a number of ways to solve this aside doing the operations one step at a time. The problem with this approach of mine is that the async operations are not made at parallel. Instead they are made one after the other which can be slow too except in cases like we do where the files in dir aren't much.

```bash
import fs from "fs";
import path from "path";

fs.readdir("ddd", (err, files)=>{
  if(err) throw new Error(err);
  const results = [];
  let isRemaining = files.length;

  files.forEach((file, index)=> {
    --isRemaining
    fs.readFile(path.join("ddd",file), (err, readContent)=>{
      if(err) throw new Error(err);
      results[index] = readContent;

      if(!isRemaining) console.log(results.toString());
    })
  })
})
```

This way all the files are called in parallel and their results saved based off their indexes so that we can access them orderly.

</LongAside>
