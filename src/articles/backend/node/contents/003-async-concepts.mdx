---
title: "Node Async and Event Loop"
description: ""
published_date: "09/07/2025"
last_updated_date: "09/07/2025"
syllabus_code: "BAC001"
authors: "kelvinsekx"
---

Node and the entire JavaScript ecosystem is built on async and the event loop fundamentals. The mastery of these topics can be liberating. But they can also be more of abstractions than concrete especially if you are new to coding.

## What's Async

When we say an operation or task runs async in Node, we mean they run **asynchronously**. This kind of tasks usually take more time to complete.
Async is both a concept and keyword in Node ( and JavaScript). We will discuss its pov as a keyword later in this lesson.

Node associates **async** operations ( or tasks) with **events**. Whenever they are triggered, they are run independently from other non-async operations. Thanks to async, tasks are not forced to wait after another. If a task takes more time (i.e async), it should be moved to a separate lane while the rest of program goes on interrupted.

Examples of async tasks ( or operations) are writing/reading a file, network fetches.

<LongAside subject="Explanation with some layman examples">
  For example, **the process of sewing by one person synchronously**. As a taylor, you can not stich a cloth until they are cut in pieces patterns. After cutting, you would have to weave (depending on the material) before sewing and so on. In a nutshell, you can not go on with another process until the first is done.

But let's use another example with **a Baker who bakes asynchromously**. They start by spreading cream while the machine is mixing the cake. If it is done to taste, you can leave what you are doing to go back to the mixed cake.

These scenarios represent Async and Sync concepts well. Async guarantees your node program can keep running while another piece of the program is doing something else that usually takes time or slow. These kind of operations are taken off the execution flow.

</LongAside>

Async events are handled by handlers. These handlers can be expressed in 3 broad patterns: **Callbacks**, **Promises** (and Async/Await) and **Listeners**.

## Callbacks

Before JavaScript empowered us with an intuitive way of handling async tasks, Node gave us Callbacks. Callbacks are functions that are called after an async task is done.

Imagine giving an instruction that if the bake is done smoothing, a sound should peep.

```bash
cake("be mixing", (err, done){
    if(!err){
        done(peep)
    }
})
```

Another example would be reading from the drive or filesystem. Until recently with faster computers, it takes a substantial time to read from drives. You don't want to delay your entire program waiting for a feedback from your drive.

**Synchronously reading a file**

```bash
import {readFileSync} from "fs";

let fileName
console.log("Hello")
// prints "Hello" -> GoToNextLine

fileName = readFileSync('file.txt')
// takes 10 secs -> call done() -> GoToNextLine

console.log(fileName)
// prints "FileName.txt" -> ends
```

**ASynchronously reading a file**

```bash
import {readFileSync} from "fs";

let fileName
console.log("Hello")
// prints "Hello" -> GoToNextLine

readFileSync('file', (err, done))
// leaves execution flow -> GoToNextLine immediately -> takes 10 secs in background -> call done()

console.log(fileName)
// prints undefined -> ends
```

<LongAside subject={'A little beyond: Async in series and parallel'}>

Although most of our examples while doing asyn operations would be with a sigle identity, in rare cases, often than not, you would have to make async operations for multiple things at a time. For example an array of items.

An example where this shine is trying to read all the files in a directory. You can either do these async operations in series or parallel. Let's make an example of reading a folder and list the length of the files in the directory/folder.

We might be tempted to do this.

```bash
fs.readdir('foldername', (err, files){
    if(err) throw new Error(err)
    files.forEach((f)=> {
        fs.readFile(f, (err, result){
            if(err){
                throw new Error(err)
            }
            console.log(result.length)
        })
    })
})
```

The problem with our former example is that the length of files would not come in the order of the files in our directory.

To solve this, we can make the operations in series. One after another, and what else algorithm shines here if not recursion. See example below:

```bash
import fs from "fs";
import path from "path";

fs.readdir("ddd", (err, files)=>{
  if(err) throw new Error(err);

  function readFiles(i){
    if(i >=files.length) return; // exit
    fs.readFile(path.join("ddd", files[i]), (err, content)=> {
        if(err) throw new Error(err);
        console.log(content.toString())
        readFiles(i+1)
    })
 }

 readFiles(0)

})
```

There are a number of ways to solve this aside doing the operations one step at a time. The problem with this approach of mine is that the async operations are not made at parallel. Instead they are made one after the other which can be slow too except in cases like we do where the files in dir aren't much.

```bash
import fs from "fs";
import path from "path";

fs.readdir("ddd", (err, files)=>{
  if(err) throw new Error(err);
  const results = [];
  let isRemaining = files.length;

  files.forEach((file, index)=> {
    --isRemaining
    fs.readFile(path.join("ddd",file), (err, readContent)=>{
      if(err) throw new Error(err);
      results[index] = readContent;

      if(!isRemaining) console.log(results.toString());
    })
  })
})
```

This way all the files are called in parallel and their results saved based off their indexes so that we can access them orderly.

</LongAside>
